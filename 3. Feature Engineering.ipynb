{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from func import outlier_counter, get_all_univariate_outlier_index\n",
    "from modelling_purpose import Xy, algorithm_report_accumulation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/imputed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With / Without Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan membuat 2 dataset dari `imputed.csv`, yaitu:\n",
    "- Dengan Outlier\n",
    "- Tanpa Outlier (Univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier = df.copy()\n",
    "outlier_columns  = ['TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "                    'YearsSinceLastPromotion', 'YearsWithCurrManager', 'TrainingTimesLastYear',\n",
    "                    'NumCompaniesWorked', 'MonthlyIncome']\n",
    "outlier_index = get_all_univariate_outlier_index(df_without_outlier, outlier_columns)\n",
    "df_without_outlier.drop(df_without_outlier.index[outlier_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_outlier.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df` adalah dataset dengan outlier. Dan `df_without_outlier` adalah dataset tanpa outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df,column):\n",
    "    df = pd.concat(\n",
    "    [\n",
    "        df,\n",
    "        pd.get_dummies(df[column], prefix=column, drop_first=True)\n",
    "    ],\n",
    "    axis=1)\n",
    "    df = df.drop(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'Gender',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'OverTime',\n",
       " 'Education',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'JobInvolvement',\n",
       " 'JobLevel',\n",
       " 'JobSatisfaction',\n",
       " 'PerformanceRating',\n",
       " 'RelationshipSatisfaction',\n",
       " 'StockOptionLevel',\n",
       " 'WorkLifeBalance']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ini hanya untuk eksplanasi ---------------\n",
    "X = df.drop('Attrition',axis=1)\n",
    "y = df['Attrition'].map({'Yes':1,'No':0})\n",
    "\n",
    "categorical_features = X.select_dtypes(include='O').columns.tolist()\n",
    "ordinal = ['Education', 'EnvironmentSatisfaction', 'JobInvolvement', 'JobLevel',\n",
    "           'JobSatisfaction', 'PerformanceRating', 'RelationshipSatisfaction',\n",
    "           'StockOptionLevel', 'WorkLifeBalance']\n",
    "categorical_features += ordinal\n",
    "categorical_features\n",
    "# Ini hanya untuk eksplanasi ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semua categorical features, entah nominal ataupun ordinal akan digabung dan diaplikasikan dengan One-Hot Encoder.\n",
    "Alasan mengapa ordinal features juga menggunakan One-Hot Encoder adalah karena pada kasus classifier, ordinal feature yang mempunyai continuous behaviour tidak berpengaruh seperti pada kasus regressor. Melakukan pe-ranking-an pada suatu feature menjadi tidak berguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada classifier problem, kita akan memilih salah satu metrik penilaian yang akan dijadikan acuan. Ini dikarenakan False Positive dan False Negative akan selalu trade-off satu sama lain. Jadinya, umumnya kita akan dihadapkan dengan 2 pilihan berikut:\n",
    "- Kasus False Negative lebih beresiko daripada kasus False Positive\n",
    "- Kasus False Positive lebih beresiko daripada kasus False Negative\n",
    "\n",
    "Di kasus ini, False Positive dan False Negative bisa diterjemahkan seperti ini:\n",
    "- FP : Pegawai yang tidak keluar, terprediksi keluar.\n",
    "- FN : Pegawai yang keluar, terprediksi tidak keluar.\n",
    "\n",
    "Untuk kasus Attrition, saya menganggap kasus **False Negative adalah yang beresiko**.\n",
    "\n",
    "Alasannya adalah, apabila ada pegawai keluar namun terprediksi tidak keluar, perusahaan beresiko kehilangan pegawai potensialnya. Dengan decision seperti ini, maka saya putuskan untuk memilih **Recall** sebagai metric yang diutamakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Xy(df)\n",
    "X_wo, y_wo = Xy(df_without_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Train Recall  Test Recall  \\\n",
       "Algorithm                                                                       \n",
       "<class 'sklearn.linear_model._logistic.Logistic...      0.007092     0.028571   \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...      1.000000     0.285714   \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...      1.000000     0.142857   \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...      0.765957     0.228571   \n",
       "<class 'sklearn.linear_model._logistic.Logistic...      0.033333     0.136364   \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...      1.000000     0.545455   \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...      1.000000     0.272727   \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...      0.922222     0.318182   \n",
       "\n",
       "                                                               Notes  \n",
       "Algorithm                                                             \n",
       "<class 'sklearn.linear_model._logistic.Logistic...     with Outliers  \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...     with Outliers  \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...     with Outliers  \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...     with Outliers  \n",
       "<class 'sklearn.linear_model._logistic.Logistic...  without Outliers  \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...  without Outliers  \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...  without Outliers  \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...  without Outliers  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_list = [LogisticRegression,DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "\n",
    "a = algorithm_report_accumulation(algorithm_list, X, y, .2, 'with Outliers')\n",
    "b = algorithm_report_accumulation(algorithm_list, X_wo, y_wo, .2, 'without Outliers')\n",
    "x = pd.concat([a, b],ignore_index=True)\n",
    "x.set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** :\n",
    "- LogisticRegression dengan default parameter underfit dengan parah. Entah di dataset dengan dan tanpa outlier, recall score tidak sampai 0.15.\n",
    "- Model lainnya (selain LogisticRegression) overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dengan temuan ini, saya tidak melanjutkan untuk menggunakan LogisticRegression. Dengan asumsi bahwa dengan score serendah itu, tentunya akan memerlukan effort lebih untuk menaikkan scorenya, meskipun menggunakan Hyperparameter Tuning. Karena pada umumnya lebih mudah untuk melakukan tuning pada model yang overfit daripada yang underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Cross Validation Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_CVS(features,target,model):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,target,random_state=11111992)\n",
    "    classification = model()\n",
    "    score = cross_val_score(classification,features, target, cv=5).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score_accumulation(algorithm_list, X, y, notes):\n",
    "    cv_score = []\n",
    "    notes_arr = []\n",
    "    for i in algorithm_list :\n",
    "        score = find_CVS(X,y,i)\n",
    "        cv_score.append(score)\n",
    "        notes_arr.append(notes)\n",
    "\n",
    "    cv_df = pd.DataFrame({\n",
    "        'Algorithm': algorithm_list,\n",
    "        'Notes': notes_arr,\n",
    "        'CV Score': cv_score\n",
    "    })\n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Notes</th>\n",
       "      <th>CV Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.779384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.854246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.763077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.847692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Notes  CV Score\n",
       "Algorithm                                                                     \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...     with Outliers  0.779384\n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...     with Outliers  0.848392\n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...     with Outliers  0.854246\n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...  without Outliers  0.763077\n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...  without Outliers  0.847692\n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...  without Outliers  0.846154"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_list = [DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "a = cv_score_accumulation(algorithm_list, X, y, 'with Outliers')\n",
    "b = cv_score_accumulation(algorithm_list, X_wo, y_wo, 'without Outliers')\n",
    "x = pd.concat([a, b],ignore_index=True)\n",
    "x.set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** : Dengan data ini ditemukan bahwa CV Score dari dataset dengan Outliers lebih baik daripada CV Score dari datest tanpa Outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maka, selanjutnya kita akan menggunakan algoritma DecisionTree, RandomForest, juga GradientBoosting menggunakan dataset dengan outliers untuk Hyperparameter Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
