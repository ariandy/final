{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from func import outlier_counter, get_all_univariate_outlier_index\n",
    "from modelling_purpose import Xy, algorithm_report_accumulation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/imputed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With / Without Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan membuat 2 dataset dari `imputed.csv`, yaitu:\n",
    "- Dengan Outlier\n",
    "- Tanpa Outlier (Univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier = df.copy()\n",
    "outlier_columns  = ['TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "                    'YearsSinceLastPromotion', 'YearsWithCurrManager', 'TrainingTimesLastYear',\n",
    "                    'NumCompaniesWorked', 'MonthlyIncome']\n",
    "outlier_index = get_all_univariate_outlier_index(df_without_outlier, outlier_columns)\n",
    "df_without_outlier.drop(df_without_outlier.index[outlier_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_outlier.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df` adalah dataset dengan outlier. Dan `df_without_outlier` adalah dataset tanpa outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df,column):\n",
    "    df = pd.concat(\n",
    "    [\n",
    "        df,\n",
    "        pd.get_dummies(df[column], prefix=column, drop_first=True)\n",
    "    ],\n",
    "    axis=1)\n",
    "    df = df.drop(columns=column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'Gender',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'OverTime',\n",
       " 'Education',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'JobInvolvement',\n",
       " 'JobLevel',\n",
       " 'JobSatisfaction',\n",
       " 'PerformanceRating',\n",
       " 'RelationshipSatisfaction',\n",
       " 'StockOptionLevel',\n",
       " 'WorkLifeBalance']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ini hanya untuk eksplanasi ---------------\n",
    "X = df.drop('Attrition',axis=1)\n",
    "y = df['Attrition'].map({'Yes':1,'No':0})\n",
    "\n",
    "categorical_features = X.select_dtypes(include='O').columns.tolist()\n",
    "ordinal = ['Education', 'EnvironmentSatisfaction', 'JobInvolvement', 'JobLevel',\n",
    "           'JobSatisfaction', 'PerformanceRating', 'RelationshipSatisfaction',\n",
    "           'StockOptionLevel', 'WorkLifeBalance']\n",
    "categorical_features += ordinal\n",
    "categorical_features\n",
    "# Ini hanya untuk eksplanasi ---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semua categorical features, entah nominal ataupun ordinal akan digabung dan diaplikasikan dengan One-Hot Encoder.\n",
    "Alasan mengapa ordinal features juga menggunakan One-Hot Encoder adalah karena pada kasus classifier, ordinal feature yang mempunyai continuous behaviour tidak berpengaruh seperti pada kasus regressor. Melakukan pe-ranking-an pada suatu feature menjadi tidak berguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada classifier problem, kita akan memilih salah satu metrik penilaian yang akan dijadikan acuan. Ini dikarenakan False Positive dan False Negative akan selalu trade-off satu sama lain. Jadinya, umumnya kita akan dihadapkan dengan 2 pilihan berikut:\n",
    "- Kasus False Negative lebih beresiko daripada kasus False Positive\n",
    "- Kasus False Positive lebih beresiko daripada kasus False Negative\n",
    "\n",
    "Di kasus ini, False Positive dan False Negative bisa diterjemahkan seperti ini:\n",
    "- FP : Pegawai yang tidak keluar, terprediksi keluar.\n",
    "- FN : Pegawai yang keluar, terprediksi tidak keluar.\n",
    "\n",
    "Untuk kasus Attrition, saya menganggap kasus **False Negative adalah yang beresiko**.\n",
    "\n",
    "Alasannya adalah, apabila ada pegawai keluar namun terprediksi tidak keluar, perusahaan beresiko kehilangan pegawai potensialnya. Dengan decision seperti ini, maka saya putuskan untuk memilih **Recall** sebagai metric yang diutamakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = Xy(df)\n",
    "X_wo, y_wo = Xy(df_without_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Train Recall  Test Recall  \\\n",
       "Algorithm                                                                       \n",
       "<class 'sklearn.linear_model._logistic.Logistic...      0.007092     0.028571   \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...      1.000000     0.285714   \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...      1.000000     0.142857   \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...      0.765957     0.228571   \n",
       "<class 'sklearn.linear_model._logistic.Logistic...      0.033333     0.136364   \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...      1.000000     0.500000   \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...      1.000000     0.181818   \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...      0.922222     0.318182   \n",
       "\n",
       "                                                               Notes  \n",
       "Algorithm                                                             \n",
       "<class 'sklearn.linear_model._logistic.Logistic...     with Outliers  \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...     with Outliers  \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...     with Outliers  \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...     with Outliers  \n",
       "<class 'sklearn.linear_model._logistic.Logistic...  without Outliers  \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...  without Outliers  \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...  without Outliers  \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...  without Outliers  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_list = [LogisticRegression,DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "\n",
    "a = algorithm_report_accumulation(algorithm_list, X, y, .2, 'with Outliers')\n",
    "b = algorithm_report_accumulation(algorithm_list, X_wo, y_wo, .2, 'without Outliers')\n",
    "x = pd.concat([a, b],ignore_index=True)\n",
    "x.set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** :\n",
    "- LogisticRegression dengan default parameter underfit dengan parah. Entah di dataset dengan dan tanpa outlier, recall score tidak sampai 0.15.\n",
    "- Model lainnya (selain LogisticRegression) overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dengan temuan ini, saya tidak melanjutkan untuk menggunakan LogisticRegression. Dengan asumsi bahwa dengan score serendah itu, tentunya akan memerlukan effort lebih untuk menaikkan scorenya, meskipun menggunakan Hyperparameter Tuning. Karena pada umumnya lebih mudah untuk melakukan tuning pada model yang overfit daripada yang underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Cross Validation Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_CVS(features,target,model, partition, scoring_system):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,target,random_state=11111992)\n",
    "    classification = model()\n",
    "    score = cross_val_score(classification,features, target, cv=partition, scoring=scoring_system).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score_accumulation(algorithm_list, X, y, partition, scoring_system, notes):\n",
    "    cv_score = []\n",
    "    notes_arr = []\n",
    "    for i in algorithm_list :\n",
    "        score = find_CVS(X,y,i, partition, scoring_system)\n",
    "        cv_score.append(score)\n",
    "        notes_arr.append(notes)\n",
    "\n",
    "    cv_df = pd.DataFrame({\n",
    "        'Algorithm': algorithm_list,\n",
    "        'Notes': notes_arr,\n",
    "        'CV Score': cv_score\n",
    "    })\n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Notes</th>\n",
       "      <th>CV Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.357708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.352381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.295397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.259684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.197233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.152857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               Notes  CV Score\n",
       "Algorithm                                                                     \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...  without Outliers  0.357708\n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...     with Outliers  0.352381\n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...     with Outliers  0.295397\n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...  without Outliers  0.259684\n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...  without Outliers  0.197233\n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...     with Outliers  0.152857"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_list = [DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "a = cv_score_accumulation(algorithm_list, X, y, 5, 'recall', 'with Outliers')\n",
    "b = cv_score_accumulation(algorithm_list, X_wo, y_wo, 5, 'recall', 'without Outliers')\n",
    "x = pd.concat([a, b],ignore_index=True)\n",
    "x.set_index('Algorithm').sort_values(by='CV Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** : Dengan split sebanyak 5 dan recall-scoring, ditemukan bahwa CV Score dari dataset dengan Outliers lebih baik daripada CV Score dari datest tanpa Outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maka, selanjutnya kita akan menggunakan algoritma DecisionTree, RandomForest, juga GradientBoosting menggunakan dataset dengan outliers untuk Hyperparameter Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_list = [DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=11111992)\n",
    "\n",
    "def pipelining(algorithm):\n",
    "    model_pipeline = Pipeline([\n",
    "        ('pca', PCA()),\n",
    "        ('algorithm', algorithm())\n",
    "    ])\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_for_DecisionTreeClassifier = {\n",
    "    'pca__n_components': [10,15,20],\n",
    "    'algorithm__random_state': [11111992],\n",
    "    'algorithm__splitter' : ['best', 'random'],\n",
    "    'algorithm__max_features' : list(range(1,X_train.shape[1])),\n",
    "    'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
    "    # 'algorithm__class_weight': [{0: x, 1: 1.0-x} for x in np.linspace(0.05, 0.95, 20)], ----> Terlalu berat\n",
    "    # 'algorithm__class_weight': [{0: 0.75, 1: 0.25}, {0: 0.7, 1: 0.3}, {0: 0.8, 1: 0.2}], ---> Masih berat\n",
    "    'algorithm__max_depth' : np.linspace(4, 15, 10, endpoint=True),\n",
    "    'algorithm__min_samples_split' : [200,300,400],\n",
    "    'algorithm__min_samples_leaf' : [100,150,200],\n",
    "}\n",
    "\n",
    "## _________________________________________________________________________________ Purpose :\n",
    "# DecisionTreeClassifier()\n",
    "## _________________________________________________________________________________ Report :\n",
    "# Fitting 5 folds for each of 32940 candidates, totalling 164700 fits\n",
    "# [Parallel(n_jobs=-1)]: Done 164700 out of 164700 | elapsed: 16.5min finished\n",
    "## _________________________________________________________________________________ Verbose Output :\n",
    "# GridSearchCV(cv=5,\n",
    "#              estimator=Pipeline(steps=[('pca', PCA()),\n",
    "#                                        ('algorithm',\n",
    "#                                         DecisionTreeClassifier())]),\n",
    "#              n_jobs=-1,\n",
    "#              param_grid={'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
    "#                          'algorithm__max_depth': array([ 4.        ,  5.22222222,  6.44444444,  7.66666667,  8.88888889,\n",
    "#        10.11111111, 11.33333333, 12.55555556, 13.77777778, 15.        ]),\n",
    "#                          'algorithm__max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
    "#                                                      10, 11, 12, 13, 14, 15, 16,\n",
    "#                                                      17, 18, 19, 20, 21, 22, 23,\n",
    "#                                                      24, 25, 26, 27, 28, 29, 30, ...],\n",
    "#                          'algorithm__min_samples_leaf': [100, 150, 200],\n",
    "#                          'algorithm__min_samples_split': [200, 300, 400],\n",
    "#                          'algorithm__random_state': [11111992],\n",
    "#                          'algorithm__splitter': ['best', 'random'],\n",
    "#                          'pca__n_components': [10, 15, 20]},\n",
    "#              scoring='recall', verbose=1)\n",
    "## _________________________________________________________________________________ grid.best_params_\n",
    "# {'algorithm__class_weight': {0: 1, 1: 4.75},\n",
    "#  'algorithm__max_depth': 4.0,\n",
    "#  'algorithm__max_features': 1,\n",
    "#  'algorithm__min_samples_leaf': 100,\n",
    "#  'algorithm__min_samples_split': 200,\n",
    "#  'algorithm__random_state': 11111992,\n",
    "#  'algorithm__splitter': 'random',\n",
    "#  'pca__n_components': 10}\n",
    "\n",
    "params_for_RandomForestClassifier = {\n",
    "    'pca__n_components': [10,15,20],\n",
    "    'algorithm__random_state': [11111992],\n",
    "    'algorithm__max_features' : list(range(1,X_train.shape[1])),\n",
    "    'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
    "    'algorithm__max_depth' : np.linspace(4, 15, 10, endpoint=True),\n",
    "    'algorithm__min_samples_split' : [200,300,400],\n",
    "    'algorithm__min_samples_leaf' : [100,150,200],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipelining(DecisionTreeClassifier), params, cv=5, scoring='recall', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32940 candidates, totalling 164700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1260 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=-1)]: Done 3260 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6060 tasks      | elapsed:   43.8s\n",
      "[Parallel(n_jobs=-1)]: Done 9660 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14060 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 19260 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 25260 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 32060 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 39660 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 48060 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 57260 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 67260 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done 78060 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 89660 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 102060 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 115260 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 129260 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 144060 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done 159660 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 164700 out of 164700 | elapsed: 16.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('pca', PCA()),\n",
       "                                       ('algorithm',\n",
       "                                        DecisionTreeClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
       "                         'algorithm__max_depth': array([ 4.        ,  5.22222222,  6.44444444,  7.66666667,  8.88888889,\n",
       "       10.11111111, 11.33333333, 12.55555556, 13.77777778, 15.        ]),\n",
       "                         'algorithm__max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                     10, 11, 12, 13, 14, 15, 16,\n",
       "                                                     17, 18, 19, 20, 21, 22, 23,\n",
       "                                                     24, 25, 26, 27, 28, 29, 30, ...],\n",
       "                         'algorithm__min_samples_leaf': [100, 150, 200],\n",
       "                         'algorithm__min_samples_split': [200, 300, 400],\n",
       "                         'algorithm__random_state': [11111992],\n",
       "                         'algorithm__splitter': ['best', 'random'],\n",
       "                         'pca__n_components': [10, 15, 20]},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%script false --no-raise-error\n",
    "grid.fit(X_train, y_train) # for DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm__class_weight': {0: 1, 1: 4.75},\n",
       " 'algorithm__max_depth': 4.0,\n",
       " 'algorithm__max_features': 1,\n",
       " 'algorithm__min_samples_leaf': 100,\n",
       " 'algorithm__min_samples_split': 200,\n",
       " 'algorithm__random_state': 11111992,\n",
       " 'algorithm__splitter': 'random',\n",
       " 'pca__n_components': 10}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_algorithm__class_weight</th>\n",
       "      <th>param_algorithm__max_depth</th>\n",
       "      <th>param_algorithm__max_features</th>\n",
       "      <th>param_algorithm__min_samples_leaf</th>\n",
       "      <th>param_algorithm__min_samples_split</th>\n",
       "      <th>param_algorithm__random_state</th>\n",
       "      <th>...</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052028</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.001052</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.501140</td>\n",
       "      <td>0.076124</td>\n",
       "      <td>6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015970</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.006762</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>3667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.629630</td>\n",
       "      <td>0.621652</td>\n",
       "      <td>0.091703</td>\n",
       "      <td>2071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>0.007029</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.864957</td>\n",
       "      <td>0.075223</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.018503</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.013315</td>\n",
       "      <td>0.011076</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.220798</td>\n",
       "      <td>0.188082</td>\n",
       "      <td>7381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32935</th>\n",
       "      <td>0.017221</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32936</th>\n",
       "      <td>0.018153</td>\n",
       "      <td>0.001917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32937</th>\n",
       "      <td>0.015956</td>\n",
       "      <td>0.003959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32938</th>\n",
       "      <td>0.026303</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32939</th>\n",
       "      <td>0.019210</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{0: 1, 1: 4.75}</td>\n",
       "      <td>15</td>\n",
       "      <td>61</td>\n",
       "      <td>200</td>\n",
       "      <td>400</td>\n",
       "      <td>11111992</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>{'algorithm__class_weight': {0: 1, 1: 4.75}, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32940 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.052028      0.023372         0.006820        0.001052   \n",
       "1           0.015970      0.004384         0.006762        0.001772   \n",
       "2           0.021178      0.002208         0.007619        0.000248   \n",
       "3           0.016053      0.001422         0.007029        0.001068   \n",
       "4           0.018503      0.001096         0.013315        0.011076   \n",
       "...              ...           ...              ...             ...   \n",
       "32935       0.017221      0.001922         0.000000        0.000000   \n",
       "32936       0.018153      0.001917         0.000000        0.000000   \n",
       "32937       0.015956      0.003959         0.000000        0.000000   \n",
       "32938       0.026303      0.008191         0.000000        0.000000   \n",
       "32939       0.019210      0.004905         0.000000        0.000000   \n",
       "\n",
       "      param_algorithm__class_weight param_algorithm__max_depth  \\\n",
       "0                   {0: 1, 1: 4.75}                          4   \n",
       "1                   {0: 1, 1: 4.75}                          4   \n",
       "2                   {0: 1, 1: 4.75}                          4   \n",
       "3                   {0: 1, 1: 4.75}                          4   \n",
       "4                   {0: 1, 1: 4.75}                          4   \n",
       "...                             ...                        ...   \n",
       "32935               {0: 1, 1: 4.75}                         15   \n",
       "32936               {0: 1, 1: 4.75}                         15   \n",
       "32937               {0: 1, 1: 4.75}                         15   \n",
       "32938               {0: 1, 1: 4.75}                         15   \n",
       "32939               {0: 1, 1: 4.75}                         15   \n",
       "\n",
       "      param_algorithm__max_features param_algorithm__min_samples_leaf  \\\n",
       "0                                 1                               100   \n",
       "1                                 1                               100   \n",
       "2                                 1                               100   \n",
       "3                                 1                               100   \n",
       "4                                 1                               100   \n",
       "...                             ...                               ...   \n",
       "32935                            61                               200   \n",
       "32936                            61                               200   \n",
       "32937                            61                               200   \n",
       "32938                            61                               200   \n",
       "32939                            61                               200   \n",
       "\n",
       "      param_algorithm__min_samples_split param_algorithm__random_state  ...  \\\n",
       "0                                    200                      11111992  ...   \n",
       "1                                    200                      11111992  ...   \n",
       "2                                    200                      11111992  ...   \n",
       "3                                    200                      11111992  ...   \n",
       "4                                    200                      11111992  ...   \n",
       "...                                  ...                           ...  ...   \n",
       "32935                                400                      11111992  ...   \n",
       "32936                                400                      11111992  ...   \n",
       "32937                                400                      11111992  ...   \n",
       "32938                                400                      11111992  ...   \n",
       "32939                                400                      11111992  ...   \n",
       "\n",
       "      param_pca__n_components  \\\n",
       "0                          10   \n",
       "1                          15   \n",
       "2                          20   \n",
       "3                          10   \n",
       "4                          15   \n",
       "...                       ...   \n",
       "32935                      15   \n",
       "32936                      20   \n",
       "32937                      10   \n",
       "32938                      15   \n",
       "32939                      20   \n",
       "\n",
       "                                                  params split0_test_score  \\\n",
       "0      {'algorithm__class_weight': {0: 1, 1: 4.75}, '...          0.370370   \n",
       "1      {'algorithm__class_weight': {0: 1, 1: 4.75}, '...          0.592593   \n",
       "2      {'algorithm__class_weight': {0: 1, 1: 4.75}, '...          0.555556   \n",
       "3      {'algorithm__class_weight': {0: 1, 1: 4.75}, '...          0.777778   \n",
       "4      {'algorithm__class_weight': {0: 1, 1: 4.75}, '...          0.000000   \n",
       "...                                                  ...               ...   \n",
       "32935  {'algorithm__class_weight': {0: 1, 1: 4.75}, '...               NaN   \n",
       "32936  {'algorithm__class_weight': {0: 1, 1: 4.75}, '...               NaN   \n",
       "32937  {'algorithm__class_weight': {0: 1, 1: 4.75}, '...               NaN   \n",
       "32938  {'algorithm__class_weight': {0: 1, 1: 4.75}, '...               NaN   \n",
       "32939  {'algorithm__class_weight': {0: 1, 1: 4.75}, '...               NaN   \n",
       "\n",
       "       split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0               0.576923           0.500000           0.576923   \n",
       "1               0.769231           0.500000           0.653846   \n",
       "2               0.769231           0.500000           0.653846   \n",
       "3               0.923077           0.961538           0.884615   \n",
       "4               0.000000           0.461538           0.346154   \n",
       "...                  ...                ...                ...   \n",
       "32935                NaN                NaN                NaN   \n",
       "32936                NaN                NaN                NaN   \n",
       "32937                NaN                NaN                NaN   \n",
       "32938                NaN                NaN                NaN   \n",
       "32939                NaN                NaN                NaN   \n",
       "\n",
       "       split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.481481         0.501140        0.076124             6157  \n",
       "1               0.407407         0.584615        0.124500             3667  \n",
       "2               0.629630         0.621652        0.091703             2071  \n",
       "3               0.777778         0.864957        0.075223                1  \n",
       "4               0.296296         0.220798        0.188082             7381  \n",
       "...                  ...              ...             ...              ...  \n",
       "32935                NaN              NaN             NaN            14212  \n",
       "32936                NaN              NaN             NaN            14211  \n",
       "32937                NaN              NaN             NaN            14210  \n",
       "32938                NaN              NaN             NaN            28961  \n",
       "32939                NaN              NaN             NaN            32940  \n",
       "\n",
       "[32940 rows x 21 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=10)),\n",
       "                ('algorithm',\n",
       "                 DecisionTreeClassifier(class_weight={0: 1, 1: 4.75},\n",
       "                                        max_depth=4.0, max_features=1,\n",
       "                                        min_samples_leaf=100,\n",
       "                                        min_samples_split=200,\n",
       "                                        random_state=11111992,\n",
       "                                        splitter='random'))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8649572649572651"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8560606060606061"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.23      0.37       639\n",
      "           1       0.19      0.86      0.31       132\n",
      "\n",
      "    accuracy                           0.34       771\n",
      "   macro avg       0.54      0.54      0.34       771\n",
      "weighted avg       0.77      0.34      0.36       771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred = grid.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.28      0.43       214\n",
      "           1       0.21      0.95      0.35        44\n",
      "\n",
      "    accuracy                           0.39       258\n",
      "   macro avg       0.59      0.62      0.39       258\n",
      "weighted avg       0.84      0.39      0.42       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################################################################################### Random Forest\n"
     ]
    }
   ],
   "source": [
    "print('######################################################################################################### Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipelining(RandomForestClassifier), params_for_RandomForestClassifier, cv=5, scoring='recall', n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16470 candidates, totalling 82350 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:   38.1s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed:  9.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14442 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 18042 tasks      | elapsed: 14.7min\n",
      "[Parallel(n_jobs=-1)]: Done 19992 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 22042 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 24192 tasks      | elapsed: 18.3min\n",
      "[Parallel(n_jobs=-1)]: Done 26442 tasks      | elapsed: 21.1min\n",
      "[Parallel(n_jobs=-1)]: Done 28792 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 31242 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 33792 tasks      | elapsed: 26.1min\n",
      "[Parallel(n_jobs=-1)]: Done 36442 tasks      | elapsed: 28.5min\n",
      "[Parallel(n_jobs=-1)]: Done 39192 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 42042 tasks      | elapsed: 32.1min\n",
      "[Parallel(n_jobs=-1)]: Done 44992 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done 48042 tasks      | elapsed: 36.2min\n",
      "[Parallel(n_jobs=-1)]: Done 51192 tasks      | elapsed: 39.4min\n",
      "[Parallel(n_jobs=-1)]: Done 54442 tasks      | elapsed: 41.4min\n",
      "[Parallel(n_jobs=-1)]: Done 57792 tasks      | elapsed: 43.2min\n",
      "[Parallel(n_jobs=-1)]: Done 61242 tasks      | elapsed: 46.7min\n",
      "[Parallel(n_jobs=-1)]: Done 64792 tasks      | elapsed: 48.5min\n",
      "[Parallel(n_jobs=-1)]: Done 68442 tasks      | elapsed: 52.2min\n",
      "[Parallel(n_jobs=-1)]: Done 72192 tasks      | elapsed: 54.1min\n",
      "[Parallel(n_jobs=-1)]: Done 76042 tasks      | elapsed: 57.6min\n",
      "[Parallel(n_jobs=-1)]: Done 79992 tasks      | elapsed: 59.9min\n",
      "[Parallel(n_jobs=-1)]: Done 82350 out of 82350 | elapsed: 61.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('pca', PCA()),\n",
       "                                       ('algorithm',\n",
       "                                        RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
       "                         'algorithm__max_depth': array([ 4.        ,  5.22222222,  6.44444444,  7.66666667,  8.88888889,\n",
       "       10.11111111, 11.33333333, 12.55555556, 13.77777778, 15.        ]),\n",
       "                         'algorithm__max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                     10, 11, 12, 13, 14, 15, 16,\n",
       "                                                     17, 18, 19, 20, 21, 22, 23,\n",
       "                                                     24, 25, 26, 27, 28, 29, 30, ...],\n",
       "                         'algorithm__min_samples_leaf': [100, 150, 200],\n",
       "                         'algorithm__min_samples_split': [200, 300, 400],\n",
       "                         'algorithm__random_state': [11111992],\n",
       "                         'pca__n_components': [10, 15, 20]},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm__class_weight': {0: 1, 1: 4.75},\n",
       " 'algorithm__max_depth': 5.222222222222222,\n",
       " 'algorithm__max_features': 18,\n",
       " 'algorithm__min_samples_leaf': 150,\n",
       " 'algorithm__min_samples_split': 300,\n",
       " 'algorithm__random_state': 11111992,\n",
       " 'pca__n_components': 20}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6290598290598289"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454545454545453"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80       639\n",
      "           1       0.32      0.64      0.42       132\n",
      "\n",
      "    accuracy                           0.70       771\n",
      "   macro avg       0.61      0.68      0.61       771\n",
      "weighted avg       0.80      0.70      0.74       771\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_train)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.74      0.80       214\n",
      "           1       0.26      0.45      0.33        44\n",
      "\n",
      "    accuracy                           0.69       258\n",
      "   macro avg       0.57      0.60      0.57       258\n",
      "weighted avg       0.76      0.69      0.72       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.        ,  5.22222222,  6.44444444,  7.66666667,  8.88888889,\n",
       "       10.11111111, 11.33333333, 12.55555556, 13.77777778, 15.        ])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(4, 15, 10, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05      , 0.09736842, 0.14473684, 0.19210526, 0.23947368,\n",
       "       0.28684211, 0.33421053, 0.38157895, 0.42894737, 0.47631579,\n",
       "       0.52368421, 0.57105263, 0.61842105, 0.66578947, 0.71315789,\n",
       "       0.76052632, 0.80789474, 0.85526316, 0.90263158, 0.95      ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.linspace(0.05, 0.95, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x(m1, m2, m3, l):\n",
    "    m_total = (m1+m2+m3)/3\n",
    "    m_total = m_total*40/100\n",
    "    l = l / 10\n",
    "    return m_total + l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 20]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(x) for x in np.linspace(4, 20, num = 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4., 20.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(4, 20, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
