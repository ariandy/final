{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from func import outlier_counter, get_all_univariate_outlier_index\n",
    "from modelling_purpose import Xy, algorithm_report_accumulation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/imputed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With / Without Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan membuat 2 dataset dari `imputed.csv`, yaitu:\n",
    "- Dengan Outlier\n",
    "- Tanpa Outlier (Univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier = df.copy()\n",
    "outlier_columns  = ['TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "                    'YearsSinceLastPromotion', 'YearsWithCurrManager', 'TrainingTimesLastYear',\n",
    "                    'NumCompaniesWorked', 'MonthlyIncome']\n",
    "outlier_index = get_all_univariate_outlier_index(df_without_outlier, outlier_columns)\n",
    "df_without_outlier.drop(df_without_outlier.index[outlier_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_outlier.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df` adalah dataset dengan outlier. Dan `df_without_outlier` adalah dataset tanpa outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'Gender',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'OverTime']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Attrition',axis=1)\n",
    "y = df['Attrition'].map({'Yes':1,'No':0})\n",
    "X_wo = df_without_outlier.drop('Attrition',axis=1)\n",
    "y_wo = df_without_outlier['Attrition'].map({'Yes':1,'No':0})\n",
    "\n",
    "categorical_features = X.select_dtypes(include='O').columns.tolist()\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semua categorical features, entah nominal ataupun ordinal akan digabung dan diaplikasikan dengan One-Hot Encoder.\n",
    "Alasan mengapa ordinal features juga menggunakan One-Hot Encoder adalah karena pada kasus classifier, ordinal feature yang mempunyai continuous behaviour tidak berpengaruh seperti pada kasus regressor. Melakukan pe-ranking-an pada suatu feature menjadi tidak berguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "X_wo = pd.get_dummies(X_wo, columns=categorical_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada classifier problem, kita akan memilih salah satu metrik penilaian yang akan dijadikan acuan. Ini dikarenakan False Positive dan False Negative akan selalu trade-off satu sama lain. Jadinya, umumnya kita akan dihadapkan dengan 2 pilihan berikut:\n",
    "- Kasus False Negative lebih beresiko daripada kasus False Positive\n",
    "- Kasus False Positive lebih beresiko daripada kasus False Negative\n",
    "\n",
    "Di kasus ini, False Positive dan False Negative bisa diterjemahkan seperti ini:\n",
    "- FP : Pegawai yang tidak keluar, terprediksi keluar.\n",
    "- FN : Pegawai yang keluar, terprediksi tidak keluar.\n",
    "\n",
    "Untuk kasus Attrition, saya menganggap kasus **False Negative adalah yang beresiko**.\n",
    "\n",
    "Alasannya adalah, apabila ada pegawai keluar namun terprediksi tidak keluar, perusahaan beresiko kehilangan pegawai potensialnya. Dengan decision seperti ini, maka saya putuskan untuk memilih **Recall** sebagai metric yang diutamakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>0.858156</td>\n",
       "      <td>0.342857</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Train Recall  Test Recall  \\\n",
       "Algorithm                                                                       \n",
       "<class 'sklearn.linear_model._logistic.Logistic...      0.014184     0.000000   \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...      1.000000     0.285714   \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...      1.000000     0.085714   \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...      0.858156     0.342857   \n",
       "<class 'sklearn.linear_model._logistic.Logistic...      0.144444     0.136364   \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...      1.000000     0.500000   \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...      1.000000     0.227273   \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...      0.933333     0.409091   \n",
       "\n",
       "                                                               Notes  \n",
       "Algorithm                                                             \n",
       "<class 'sklearn.linear_model._logistic.Logistic...     with Outliers  \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...     with Outliers  \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...     with Outliers  \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...     with Outliers  \n",
       "<class 'sklearn.linear_model._logistic.Logistic...  without Outliers  \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...  without Outliers  \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...  without Outliers  \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...  without Outliers  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_list = [LogisticRegression,DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "\n",
    "a = algorithm_report_accumulation(algorithm_list, X, y, .2, 'with Outliers')\n",
    "b = algorithm_report_accumulation(algorithm_list, X_wo, y_wo, .2, 'without Outliers')\n",
    "x = pd.concat([a, b],ignore_index=True)\n",
    "x.set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** :\n",
    "- LogisticRegression dengan default parameter underfit dengan parah. Entah di dataset dengan dan tanpa outlier, recall score tidak sampai 0.15.\n",
    "- Model lainnya (selain LogisticRegression) overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dengan temuan ini, saya tidak melanjutkan untuk menggunakan LogisticRegression. Dengan asumsi bahwa dengan score serendah itu, tentunya akan memerlukan effort lebih untuk menaikkan scorenya, meskipun menggunakan Hyperparameter Tuning. Karena pada umumnya lebih mudah untuk melakukan tuning pada model yang overfit daripada yang underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Cross Validation Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_CVS(features,target,model, partition, scoring_system):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,target,random_state=11111992)\n",
    "    classification = model()\n",
    "    score = cross_val_score(classification,features, target, cv=partition, scoring=scoring_system).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score_accumulation(algorithm_list, X, y, partition, scoring_system, notes):\n",
    "    cv_score = []\n",
    "    notes_arr = []\n",
    "    for i in algorithm_list :\n",
    "        score = find_CVS(X,y,i, partition, scoring_system)\n",
    "        cv_score.append(score)\n",
    "        notes_arr.append(notes)\n",
    "\n",
    "    cv_df = pd.DataFrame({\n",
    "        'Algorithm': algorithm_list,\n",
    "        'Notes': notes_arr,\n",
    "        'CV Score': cv_score\n",
    "    })\n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Notes</th>\n",
       "      <th>CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;class 'sklearn.tree._classes.DecisionTreeClas...</td>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.380794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.175714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._gb.GradientBoostingC...</td>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.307143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Algorithm          Notes  CV Score\n",
       "0  <class 'sklearn.tree._classes.DecisionTreeClas...  with Outliers  0.380794\n",
       "1  <class 'sklearn.ensemble._forest.RandomForestC...  with Outliers  0.175714\n",
       "2  <class 'sklearn.ensemble._gb.GradientBoostingC...  with Outliers  0.307143"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_list = [DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "a = cv_score_accumulation(algorithm_list, X, y, 5, 'recall', 'with Outliers')\n",
    "b = cv_score_accumulation(algorithm_list, X_wo, y_wo, 5, 'recall', 'without Outliers')\n",
    "# x = pd.concat([a, b],ignore_index=True)\n",
    "# x.set_index('Algorithm').sort_values(by='CV Score', ascending=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Notes</th>\n",
       "      <th>CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;class 'sklearn.tree._classes.DecisionTreeClas...</td>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.339921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.188933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._gb.GradientBoostingC...</td>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.330830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Algorithm             Notes  \\\n",
       "0  <class 'sklearn.tree._classes.DecisionTreeClas...  without Outliers   \n",
       "1  <class 'sklearn.ensemble._forest.RandomForestC...  without Outliers   \n",
       "2  <class 'sklearn.ensemble._gb.GradientBoostingC...  without Outliers   \n",
       "\n",
       "   CV Score  \n",
       "0  0.339921  \n",
       "1  0.188933  \n",
       "2  0.330830  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** : Dengan split sebanyak 5 dan recall-scoring, ditemukan bahwa urutan algoritma tidak berubah dengan ada atau tidaknya outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapun saya memilih dataset dengan outliers karena pertimbangan berikut:\n",
    "- Dengan memilih dataset tanpa outlier, maka jumlah rows berkurang sangat banyak. Dan ini berpengaruh dengan karakteristik data.\n",
    "- Pada EDA, meskipun dianggap univariate outlier, namun secara keseluruhan ia bukan multivariate outliers (based on Mahalanobis Distance)\n",
    "- According to the rank, dengan adanya outliers ataupun tidak, tidak membuat urutan algoritma tersebut berubah. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maka, selanjutnya kita akan menggunakan algoritma DecisionTree, RandomForest, juga GradientBoosting menggunakan dataset dengan outliers untuk Hyperparameter Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_list = [\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier\n",
    "]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=11111992)\n",
    "\n",
    "def pipelining(algorithm):\n",
    "    model_pipeline = Pipeline([\n",
    "        ('pca', PCA()),\n",
    "        ('algorithm', algorithm())\n",
    "    ])\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_for_DecisionTreeClassifier = {\n",
    "    'pca__n_components': [10,15,20],\n",
    "    'algorithm__random_state': [11111992],\n",
    "    'algorithm__splitter' : ['best', 'random'],\n",
    "    'algorithm__max_features' : list(range(1,X_train.shape[1])),\n",
    "#     'algorithm__class_weight': [{0: 1, 1: 4.75}], ----> Bisa dicoba di laptop\n",
    "#     'algorithm__class_weight': [{0: x, 1: 1.0-x} for x in np.linspace(0.05, 0.95, 20)], ----> Terlalu berat\n",
    "#     'algorithm__class_weight': [{0: 0.75, 1: 0.25}, {0: 0.7, 1: 0.3}, {0: 0.8, 1: 0.2}], ---> Masih berat\n",
    "    'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
    "    'algorithm__max_depth' : np.linspace(4, 15, 10),\n",
    "    'algorithm__min_samples_split' : [200,300,400],\n",
    "    'algorithm__min_samples_leaf' : [100,150,200],\n",
    "}\n",
    "\n",
    "params_for_RandomForestClassifier = {\n",
    "    'pca__n_components': [10,15,20],\n",
    "    'algorithm__n_estimators': [100,300,500,700],\n",
    "    'algorithm__random_state': [11111992],\n",
    "#     'algorithm__max_features' : list(range(1,X_train.shape[1])),\n",
    "    'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
    "    'algorithm__max_depth' : np.linspace(4, 15, 10),\n",
    "    'algorithm__min_samples_split' : [200,300,400],\n",
    "    'algorithm__min_samples_leaf' : [100,150,200],\n",
    "}\n",
    "\n",
    "params_for_GradientBoostingClassifier = {\n",
    "    'pca__n_components': [10,15,20],\n",
    "#     'algorithm__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "#     'algorithm__loss':[\"deviance\",\"exponential\"],\n",
    "    'algorithm__random_state': [11111992],\n",
    "    'algorithm__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "    'algorithm__n_estimators': [100,400,800],\n",
    "#     'algorithm__min_samples_split' : [200,300,400],\n",
    "#     'algorithm__min_samples_leaf' : [100,150,200],\n",
    "    'algorithm__max_depth' : np.linspace(4, 20, 4),\n",
    "    'algorithm__subsample': [0.7,0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Fitting 5 folds for each of 23220 candidates, totalling 116100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2280 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4544 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=-1)]: Done 7464 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=-1)]: Done 11024 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15240 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 20096 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 25608 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 31760 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 38568 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 46016 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 54120 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 62864 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 72264 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 82304 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done 93000 tasks      | elapsed:  9.2min\n",
      "[Parallel(n_jobs=-1)]: Done 104336 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 116100 out of 116100 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 16.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 5400 out of 5400 | elapsed: 26.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 43.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 54.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed: 60.5min finished\n"
     ]
    }
   ],
   "source": [
    "params_list = [\n",
    "    params_for_DecisionTreeClassifier,\n",
    "    params_for_RandomForestClassifier,\n",
    "    params_for_GradientBoostingClassifier\n",
    "]\n",
    "\n",
    "grid_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    grid = GridSearchCV(pipelining(algorithm_list[i]),\n",
    "                        params_list[i],\n",
    "                        cv=5, scoring='recall', n_jobs=-1, verbose=2)\n",
    "    print(algorithm_list[i])\n",
    "    grid.fit(X_train, y_train)\n",
    "    grid_list.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "grid.fit(X_train, y_train) # for DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################################### Report\n"
     ]
    }
   ],
   "source": [
    "print('################################################################################################### Report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Pipeline(steps=[('pca', PCA(n_components=10)),\n",
      "                ('algorithm',\n",
      "                 DecisionTreeClassifier(class_weight={0: 1, 1: 4.75},\n",
      "                                        max_depth=4.0, max_features=1,\n",
      "                                        min_samples_leaf=100,\n",
      "                                        min_samples_split=200,\n",
      "                                        random_state=11111992,\n",
      "                                        splitter='random'))])\n",
      "-----------------------------\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Pipeline(steps=[('pca', PCA(n_components=20)),\n",
      "                ('algorithm',\n",
      "                 RandomForestClassifier(class_weight={0: 1, 1: 4.75},\n",
      "                                        max_depth=5.222222222222222,\n",
      "                                        min_samples_leaf=150,\n",
      "                                        min_samples_split=200, n_estimators=300,\n",
      "                                        random_state=11111992))])\n",
      "-----------------------------\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Pipeline(steps=[('pca', PCA(n_components=20)),\n",
      "                ('algorithm',\n",
      "                 GradientBoostingClassifier(learning_rate=0.5, max_depth=4.0,\n",
      "                                            random_state=11111992,\n",
      "                                            subsample=0.7))])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('-----------------------------')\n",
    "    print(algorithm_list[i])\n",
    "    print(grid_list[i].best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm__class_weight': {0: 1, 1: 4.75},\n",
       " 'algorithm__max_depth': 4.0,\n",
       " 'algorithm__max_features': 1,\n",
       " 'algorithm__min_samples_leaf': 100,\n",
       " 'algorithm__min_samples_split': 200,\n",
       " 'algorithm__random_state': 11111992,\n",
       " 'algorithm__splitter': 'random',\n",
       " 'pca__n_components': 10}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_list[0].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm__class_weight': {0: 1, 1: 4.75},\n",
       " 'algorithm__max_depth': 5.222222222222222,\n",
       " 'algorithm__min_samples_leaf': 150,\n",
       " 'algorithm__min_samples_split': 200,\n",
       " 'algorithm__n_estimators': 300,\n",
       " 'algorithm__random_state': 11111992,\n",
       " 'pca__n_components': 20}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_list[1].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm__learning_rate': 0.5,\n",
       " 'algorithm__max_depth': 4.0,\n",
       " 'algorithm__n_estimators': 100,\n",
       " 'algorithm__random_state': 11111992,\n",
       " 'algorithm__subsample': 0.7,\n",
       " 'pca__n_components': 20}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_list[2].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "0.8649572649572651\n",
      "-----------------------------\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "0.5914529914529914\n",
      "-----------------------------\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "0.3188034188034188\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('-----------------------------')\n",
    "    print(algorithm_list[i])\n",
    "    print(grid_list[i].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.23      0.37       639\n",
      "           1       0.19      0.86      0.31       132\n",
      "\n",
      "    accuracy                           0.34       771\n",
      "   macro avg       0.54      0.54      0.34       771\n",
      "weighted avg       0.77      0.34      0.36       771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.28      0.43       214\n",
      "           1       0.21      0.95      0.35        44\n",
      "\n",
      "    accuracy                           0.39       258\n",
      "   macro avg       0.59      0.62      0.39       258\n",
      "weighted avg       0.84      0.39      0.42       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(algorithm_list[0])\n",
    "y_pred = grid_list[0].predict(X_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "y_pred = grid_list[0].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.78      0.84       639\n",
      "           1       0.37      0.63      0.47       132\n",
      "\n",
      "    accuracy                           0.75       771\n",
      "   macro avg       0.64      0.70      0.65       771\n",
      "weighted avg       0.82      0.75      0.78       771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87       214\n",
      "           1       0.42      0.61      0.50        44\n",
      "\n",
      "    accuracy                           0.79       258\n",
      "   macro avg       0.67      0.72      0.68       258\n",
      "weighted avg       0.83      0.79      0.80       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(algorithm_list[1])\n",
    "y_pred = grid_list[1].predict(X_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "y_pred = grid_list[1].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       639\n",
      "           1       1.00      1.00      1.00       132\n",
      "\n",
      "    accuracy                           1.00       771\n",
      "   macro avg       1.00      1.00      1.00       771\n",
      "weighted avg       1.00      1.00      1.00       771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       214\n",
      "           1       0.34      0.23      0.27        44\n",
      "\n",
      "    accuracy                           0.79       258\n",
      "   macro avg       0.60      0.57      0.58       258\n",
      "weighted avg       0.77      0.79      0.78       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(algorithm_list[2])\n",
    "y_pred = grid_list[2].predict(X_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "y_pred = grid_list[2].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################################################################################### End of Report\n"
     ]
    }
   ],
   "source": [
    "print('###################################################################################################### End of Report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** :\n",
    "- DecisionTreeClassifier memerlukan waktu yang lebih singkat (12 menit), namun mendapatkan score recall yang lebih baik daripada RandomForestClassifier (27 menit) dan juga GradientBoosting (61 menit)\n",
    "\n",
    "Oleh karenanya, selanjutnya saya akan menggunakan DecisionTreeClassifier dan RandomForestClassifier pada dataset dengan outlier. Akan tetapi, di notebook selanjutnya akan saya lakukan GridSearchCV sekali lagi pada 2 model ini dengan parameter yang mungkin sedikit lebih banyak daripada pada notebook ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
