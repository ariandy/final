{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library & Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from func import outlier_counter, get_all_univariate_outlier_index\n",
    "from modelling_purpose import Xy, algorithm_report_accumulation\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv/imputed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With / Without Outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita akan membuat 2 dataset dari `imputed.csv`, yaitu:\n",
    "- Dengan Outlier\n",
    "- Tanpa Outlier (Univariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_outlier = df.copy()\n",
    "outlier_columns  = ['TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "                    'YearsSinceLastPromotion', 'YearsWithCurrManager', 'TrainingTimesLastYear',\n",
    "                    'NumCompaniesWorked', 'MonthlyIncome']\n",
    "outlier_index = get_all_univariate_outlier_index(df_without_outlier, outlier_columns)\n",
    "df_without_outlier.drop(df_without_outlier.index[outlier_index], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_outlier.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df` adalah dataset dengan outlier. Dan `df_without_outlier` adalah dataset tanpa outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def one_hot(df,column):\n",
    "#     df = pd.concat(\n",
    "#     [\n",
    "#         df,\n",
    "#         pd.get_dummies(df[column], prefix=column, drop_first=True)\n",
    "#     ],\n",
    "#     axis=1)\n",
    "#     final = df.drop(columns=column)\n",
    "#     return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'Gender',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'OverTime',\n",
       " 'Education',\n",
       " 'EnvironmentSatisfaction',\n",
       " 'JobInvolvement',\n",
       " 'JobLevel',\n",
       " 'JobSatisfaction',\n",
       " 'PerformanceRating',\n",
       " 'RelationshipSatisfaction',\n",
       " 'StockOptionLevel',\n",
       " 'WorkLifeBalance']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Attrition',axis=1)\n",
    "y = df['Attrition'].map({'Yes':1,'No':0})\n",
    "X_wo = df_without_outlier.drop('Attrition',axis=1)\n",
    "y_wo = df_without_outlier['Attrition'].map({'Yes':1,'No':0})\n",
    "\n",
    "categorical_features = X.select_dtypes(include='O').columns.tolist()\n",
    "ordinal = ['Education', 'EnvironmentSatisfaction', 'JobInvolvement', 'JobLevel',\n",
    "           'JobSatisfaction', 'PerformanceRating', 'RelationshipSatisfaction',\n",
    "           'StockOptionLevel', 'WorkLifeBalance']\n",
    "for i in ordinal:\n",
    "    X[i] = X[i].astype(str)\n",
    "categorical_features += ordinal\n",
    "categorical_features = categorical_features\n",
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semua categorical features, entah nominal ataupun ordinal akan digabung dan diaplikasikan dengan One-Hot Encoder.\n",
    "Alasan mengapa ordinal features juga menggunakan One-Hot Encoder adalah karena pada kasus classifier, ordinal feature yang mempunyai continuous behaviour tidak berpengaruh seperti pada kasus regressor. Melakukan pe-ranking-an pada suatu feature menjadi tidak berguna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
    "X_wo = pd.get_dummies(X_wo, columns=categorical_features, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada classifier problem, kita akan memilih salah satu metrik penilaian yang akan dijadikan acuan. Ini dikarenakan False Positive dan False Negative akan selalu trade-off satu sama lain. Jadinya, umumnya kita akan dihadapkan dengan 2 pilihan berikut:\n",
    "- Kasus False Negative lebih beresiko daripada kasus False Positive\n",
    "- Kasus False Positive lebih beresiko daripada kasus False Negative\n",
    "\n",
    "Di kasus ini, False Positive dan False Negative bisa diterjemahkan seperti ini:\n",
    "- FP : Pegawai yang tidak keluar, terprediksi keluar.\n",
    "- FN : Pegawai yang keluar, terprediksi tidak keluar.\n",
    "\n",
    "Untuk kasus Attrition, saya menganggap kasus **False Negative adalah yang beresiko**.\n",
    "\n",
    "Alasannya adalah, apabila ada pegawai keluar namun terprediksi tidak keluar, perusahaan beresiko kehilangan pegawai potensialnya. Dengan decision seperti ini, maka saya putuskan untuk memilih **Recall** sebagai metric yang diutamakan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Recall</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>with Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.linear_model._logistic.LogisticRegression'&gt;</th>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.tree._classes.DecisionTreeClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._forest.RandomForestClassifier'&gt;</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;class 'sklearn.ensemble._gb.GradientBoostingClassifier'&gt;</th>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>without Outliers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Train Recall  Test Recall  \\\n",
       "Algorithm                                                                       \n",
       "<class 'sklearn.linear_model._logistic.Logistic...      0.007092     0.028571   \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...      1.000000     0.257143   \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...      1.000000     0.142857   \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...      0.765957     0.228571   \n",
       "<class 'sklearn.linear_model._logistic.Logistic...      0.033333     0.136364   \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...      1.000000     0.500000   \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...      1.000000     0.181818   \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...      0.922222     0.318182   \n",
       "\n",
       "                                                               Notes  \n",
       "Algorithm                                                             \n",
       "<class 'sklearn.linear_model._logistic.Logistic...     with Outliers  \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...     with Outliers  \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...     with Outliers  \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...     with Outliers  \n",
       "<class 'sklearn.linear_model._logistic.Logistic...  without Outliers  \n",
       "<class 'sklearn.tree._classes.DecisionTreeClass...  without Outliers  \n",
       "<class 'sklearn.ensemble._forest.RandomForestCl...  without Outliers  \n",
       "<class 'sklearn.ensemble._gb.GradientBoostingCl...  without Outliers  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_list = [LogisticRegression,DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "\n",
    "a = algorithm_report_accumulation(algorithm_list, X, y, .2, 'with Outliers')\n",
    "b = algorithm_report_accumulation(algorithm_list, X_wo, y_wo, .2, 'without Outliers')\n",
    "x = pd.concat([a, b],ignore_index=True)\n",
    "x.set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** :\n",
    "- LogisticRegression dengan default parameter underfit dengan parah. Entah di dataset dengan dan tanpa outlier, recall score tidak sampai 0.15.\n",
    "- Model lainnya (selain LogisticRegression) overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dengan temuan ini, saya tidak melanjutkan untuk menggunakan LogisticRegression. Dengan asumsi bahwa dengan score serendah itu, tentunya akan memerlukan effort lebih untuk menaikkan scorenya, meskipun menggunakan Hyperparameter Tuning. Karena pada umumnya lebih mudah untuk melakukan tuning pada model yang overfit daripada yang underfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Cross Validation Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_CVS(features,target,model, partition, scoring_system):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features,target,random_state=11111992)\n",
    "    classification = model()\n",
    "    score = cross_val_score(classification,features, target, cv=partition, scoring=scoring_system).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_score_accumulation(algorithm_list, X, y, partition, scoring_system, notes):\n",
    "    cv_score = []\n",
    "    notes_arr = []\n",
    "    for i in algorithm_list :\n",
    "        score = find_CVS(X,y,i, partition, scoring_system)\n",
    "        cv_score.append(score)\n",
    "        notes_arr.append(notes)\n",
    "\n",
    "    cv_df = pd.DataFrame({\n",
    "        'Algorithm': algorithm_list,\n",
    "        'Notes': notes_arr,\n",
    "        'CV Score': cv_score\n",
    "    })\n",
    "    return cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Notes</th>\n",
       "      <th>CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;class 'sklearn.tree._classes.DecisionTreeClas...</td>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.346508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.153175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._gb.GradientBoostingC...</td>\n",
       "      <td>with Outliers</td>\n",
       "      <td>0.295397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Algorithm          Notes  CV Score\n",
       "0  <class 'sklearn.tree._classes.DecisionTreeClas...  with Outliers  0.346508\n",
       "1  <class 'sklearn.ensemble._forest.RandomForestC...  with Outliers  0.153175\n",
       "2  <class 'sklearn.ensemble._gb.GradientBoostingC...  with Outliers  0.295397"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm_list = [DecisionTreeClassifier,RandomForestClassifier, GradientBoostingClassifier]\n",
    "a = cv_score_accumulation(algorithm_list, X, y, 5, 'recall', 'with Outliers')\n",
    "b = cv_score_accumulation(algorithm_list, X_wo, y_wo, 5, 'recall', 'without Outliers')\n",
    "# x = pd.concat([a, b],ignore_index=True)\n",
    "# x.set_index('Algorithm').sort_values(by='CV Score', ascending=False)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Notes</th>\n",
       "      <th>CV Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;class 'sklearn.tree._classes.DecisionTreeClas...</td>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.358498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._forest.RandomForestC...</td>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.152569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;class 'sklearn.ensemble._gb.GradientBoostingC...</td>\n",
       "      <td>without Outliers</td>\n",
       "      <td>0.259684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Algorithm             Notes  \\\n",
       "0  <class 'sklearn.tree._classes.DecisionTreeClas...  without Outliers   \n",
       "1  <class 'sklearn.ensemble._forest.RandomForestC...  without Outliers   \n",
       "2  <class 'sklearn.ensemble._gb.GradientBoostingC...  without Outliers   \n",
       "\n",
       "   CV Score  \n",
       "0  0.358498  \n",
       "1  0.152569  \n",
       "2  0.259684  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** : Dengan split sebanyak 5 dan recall-scoring, ditemukan bahwa urutan algoritma tidak berubah dengan ada atau tidaknya outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapun saya memilih dataset dengan outliers karena pertimbangan berikut:\n",
    "- Dengan memilih dataset tanpa outlier, maka jumlah rows berkurang sangat banyak. Dan ini berpengaruh dengan karakteristik data.\n",
    "- Pada EDA, meskipun dianggap univariate outlier, namun secara keseluruhan ia bukan multivariate outliers (based on Mahalanobis Distance)\n",
    "- According to the rank, dengan adanya outliers ataupun tidak, tidak membuat urutan algoritma tersebut berubah. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maka, selanjutnya kita akan menggunakan algoritma DecisionTree, RandomForest, juga GradientBoosting menggunakan dataset dengan outliers untuk Hyperparameter Tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_list = [\n",
    "    DecisionTreeClassifier,\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier\n",
    "]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=11111992)\n",
    "\n",
    "def pipelining(algorithm):\n",
    "    model_pipeline = Pipeline([\n",
    "        ('pca', PCA()),\n",
    "        ('algorithm', algorithm())\n",
    "    ])\n",
    "    return model_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_for_DecisionTreeClassifier = {\n",
    "    'pca__n_components': [10,15,20],\n",
    "    'algorithm__random_state': [11111992],\n",
    "    'algorithm__splitter' : ['best', 'random'],\n",
    "    'algorithm__max_features' : list(range(1,X_train.shape[1])),\n",
    "#     'algorithm__class_weight': [{0: 1, 1: 4.75}], ----> Bisa dicoba di laptop\n",
    "#     'algorithm__class_weight': [{0: x, 1: 1.0-x} for x in np.linspace(0.05, 0.95, 20)], ----> Terlalu berat\n",
    "#     'algorithm__class_weight': [{0: 0.75, 1: 0.25}, {0: 0.7, 1: 0.3}, {0: 0.8, 1: 0.2}], ---> Masih berat\n",
    "    'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
    "    'algorithm__max_depth' : np.linspace(4, 15, 10),\n",
    "    'algorithm__min_samples_split' : [200,300,400],\n",
    "    'algorithm__min_samples_leaf' : [100,150,200],\n",
    "}\n",
    "\n",
    "params_for_RandomForestClassifier = {\n",
    "    'pca__n_components': [10,15,20],\n",
    "    'algorithm__n_estimators': [100,300,500,700],\n",
    "    'algorithm__random_state': [11111992],\n",
    "#     'algorithm__max_features' : list(range(1,X_train.shape[1])),\n",
    "    'algorithm__class_weight': [{0: 1, 1: 4.75}],\n",
    "    'algorithm__max_depth' : np.linspace(4, 15, 10),\n",
    "    'algorithm__min_samples_split' : [200,300,400],\n",
    "    'algorithm__min_samples_leaf' : [100,150,200],\n",
    "}\n",
    "\n",
    "params_for_GradientBoostingClassifier = {\n",
    "    'pca__n_components': [10,15,20],\n",
    "#     'algorithm__criterion': [\"friedman_mse\",  \"mae\"],\n",
    "#     'algorithm__loss':[\"deviance\",\"exponential\"],\n",
    "    'algorithm__random_state': [11111992],\n",
    "    'algorithm__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.5],\n",
    "    'algorithm__n_estimators': [100,400,800],\n",
    "#     'algorithm__min_samples_split' : [200,300,400],\n",
    "#     'algorithm__min_samples_leaf' : [100,150,200],\n",
    "    'algorithm__max_depth' : np.linspace(4, 20, 4),\n",
    "    'algorithm__subsample': [0.7,0.8],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Fitting 5 folds for each of 32940 candidates, totalling 164700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 956 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2580 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4844 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 7764 tasks      | elapsed:   47.3s\n",
      "[Parallel(n_jobs=-1)]: Done 11324 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 15540 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 20396 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 25908 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 32060 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done 38868 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 46316 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 54420 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 63164 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 72564 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 82604 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=-1)]: Done 93300 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 104636 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done 116628 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=-1)]: Done 129260 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 142548 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=-1)]: Done 156476 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 164700 out of 164700 | elapsed: 14.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Fitting 5 folds for each of 1080 candidates, totalling 5400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:   44.0s\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3273 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4893 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=-1)]: Done 5400 out of 5400 | elapsed: 27.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 19.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1005 tasks      | elapsed: 30.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1450 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1977 tasks      | elapsed: 55.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2160 out of 2160 | elapsed: 61.3min finished\n"
     ]
    }
   ],
   "source": [
    "params_list = [\n",
    "    params_for_DecisionTreeClassifier,\n",
    "    params_for_RandomForestClassifier,\n",
    "    params_for_GradientBoostingClassifier\n",
    "]\n",
    "\n",
    "grid_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    grid = GridSearchCV(pipelining(algorithm_list[i]),\n",
    "                        params_list[i],\n",
    "                        cv=5, scoring='recall', n_jobs=-1, verbose=2)\n",
    "    print(algorithm_list[i])\n",
    "    grid.fit(X_train, y_train)\n",
    "    grid_list.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "grid.fit(X_train, y_train) # for DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################################################################### Report\n"
     ]
    }
   ],
   "source": [
    "print('################################################################################################### Report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Pipeline(steps=[('pca', PCA(n_components=10)),\n",
      "                ('algorithm',\n",
      "                 DecisionTreeClassifier(class_weight={0: 1, 1: 4.75},\n",
      "                                        max_depth=4.0, max_features=1,\n",
      "                                        min_samples_leaf=100,\n",
      "                                        min_samples_split=200,\n",
      "                                        random_state=11111992,\n",
      "                                        splitter='random'))])\n",
      "-----------------------------\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Pipeline(steps=[('pca', PCA(n_components=20)),\n",
      "                ('algorithm',\n",
      "                 RandomForestClassifier(class_weight={0: 1, 1: 4.75},\n",
      "                                        max_depth=4.0, min_samples_leaf=150,\n",
      "                                        min_samples_split=200, n_estimators=300,\n",
      "                                        random_state=11111992))])\n",
      "-----------------------------\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Pipeline(steps=[('pca', PCA(n_components=20)),\n",
      "                ('algorithm',\n",
      "                 GradientBoostingClassifier(learning_rate=0.5, max_depth=4.0,\n",
      "                                            random_state=11111992,\n",
      "                                            subsample=0.7))])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('-----------------------------')\n",
    "    print(algorithm_list[i])\n",
    "    print(grid_list[i].best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm__class_weight': {0: 1, 1: 4.75},\n",
       " 'algorithm__max_depth': 4.0,\n",
       " 'algorithm__max_features': 1,\n",
       " 'algorithm__min_samples_leaf': 100,\n",
       " 'algorithm__min_samples_split': 200,\n",
       " 'algorithm__random_state': 11111992,\n",
       " 'algorithm__splitter': 'random',\n",
       " 'pca__n_components': 10}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_list[0].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm__class_weight': {0: 1, 1: 4.75},\n",
       " 'algorithm__max_depth': 4.0,\n",
       " 'algorithm__min_samples_leaf': 150,\n",
       " 'algorithm__min_samples_split': 200,\n",
       " 'algorithm__n_estimators': 300,\n",
       " 'algorithm__random_state': 11111992,\n",
       " 'pca__n_components': 20}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_list[1].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm__learning_rate': 0.5,\n",
       " 'algorithm__max_depth': 4.0,\n",
       " 'algorithm__n_estimators': 100,\n",
       " 'algorithm__random_state': 11111992,\n",
       " 'algorithm__subsample': 0.7,\n",
       " 'pca__n_components': 20}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_list[2].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "0.8649572649572651\n",
      "-----------------------------\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "0.592022792022792\n",
      "-----------------------------\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "0.22763532763532765\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print('-----------------------------')\n",
    "    print(algorithm_list[i])\n",
    "    print(grid_list[i].best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.23      0.37       639\n",
      "           1       0.19      0.86      0.31       132\n",
      "\n",
      "    accuracy                           0.34       771\n",
      "   macro avg       0.54      0.54      0.34       771\n",
      "weighted avg       0.77      0.34      0.36       771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.28      0.43       214\n",
      "           1       0.21      0.95      0.35        44\n",
      "\n",
      "    accuracy                           0.39       258\n",
      "   macro avg       0.59      0.62      0.39       258\n",
      "weighted avg       0.84      0.39      0.42       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(algorithm_list[0])\n",
    "y_pred = grid_list[0].predict(X_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "y_pred = grid_list[0].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83       639\n",
      "           1       0.36      0.64      0.46       132\n",
      "\n",
      "    accuracy                           0.74       771\n",
      "   macro avg       0.64      0.70      0.65       771\n",
      "weighted avg       0.82      0.74      0.77       771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86       214\n",
      "           1       0.40      0.61      0.48        44\n",
      "\n",
      "    accuracy                           0.78       258\n",
      "   macro avg       0.65      0.71      0.67       258\n",
      "weighted avg       0.82      0.78      0.79       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(algorithm_list[1])\n",
    "y_pred = grid_list[1].predict(X_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "y_pred = grid_list[1].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       639\n",
      "           1       0.99      0.96      0.98       132\n",
      "\n",
      "    accuracy                           0.99       771\n",
      "   macro avg       0.99      0.98      0.99       771\n",
      "weighted avg       0.99      0.99      0.99       771\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.93      0.89       214\n",
      "           1       0.42      0.25      0.31        44\n",
      "\n",
      "    accuracy                           0.81       258\n",
      "   macro avg       0.64      0.59      0.60       258\n",
      "weighted avg       0.78      0.81      0.79       258\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(algorithm_list[2])\n",
    "y_pred = grid_list[2].predict(X_train)\n",
    "print(classification_report(y_train, y_pred))\n",
    "y_pred = grid_list[2].predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################################################################################### End of Report\n"
     ]
    }
   ],
   "source": [
    "print('###################################################################################################### End of Report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Temuan** :\n",
    "- DecisionTreeClassifier memerlukan waktu yang lebih singkat (15 menit), namun mendapatkan score recall yang lebih baik daripada RandomForestClassifier (27 menit) dan juga GradientBoosting (61 menit)\n",
    "\n",
    "Oleh karenanya, selanjutnya saya akan menggunakan DecisionTreeClassifier pada dataset dengan outlier. Akan tetapi, di notebook selanjutnya akan saya lakukan GridSearchCV sekali lagi pada model ini dengan parameter yang mungkin sedikit lebih banyak daripada pada notebook ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
